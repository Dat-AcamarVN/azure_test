# Chunking Implementation Guide - Simple Approach

## Tá»•ng quan

HÆ°á»›ng dáº«n nÃ y trÃ¬nh bÃ y cÃ¡ch Ã¡p dá»¥ng chunking vÃ o source code hiá»‡n táº¡i vá»›i **thay Ä‘á»•i tá»‘i thiá»ƒu**, sá»­ dá»¥ng **functions Ä‘Æ¡n giáº£n** thay vÃ¬ OOP classes.

## 1. Strategy Ä‘Æ¡n giáº£n

### 1.1 CÃ¡ch hoáº¡t Ä‘á»™ng
```
Patent lá»›n (>2KB) â†’ Chia thÃ nh chunks â†’ LÆ°u chunks + patent gá»‘c
                                    â†“
Patent nhá» (<2KB) â†’ LÆ°u trá»±c tiáº¿p â†’ KhÃ´ng thay Ä‘á»•i
```

### 1.2 Cáº¥u trÃºc dá»¯ liá»‡u
```json
// Patent gá»‘c (khÃ´ng thay Ä‘á»•i)
{
  "id": "patent_id",
  "patent_id": "patent_id",
  "title": "Patent Title",
  "abstract": "Short abstract...",
  "is_chunked": true,        // Field má»›i
  "chunk_count": 3           // Field má»›i
}

// Chunks (lÆ°u riÃªng)
{
  "id": "chunk_uuid",
  "patent_id": "patent_id",
  "chunk_type": "abstract",
  "chunk_order": 0,
  "chunk_text": "Text content...",
  "chunk_size": 1500
}
```

## 2. Implementation vá»›i thay Ä‘á»•i tá»‘i thiá»ƒu

### 2.1 ThÃªm functions má»›i (khÃ´ng thay Ä‘á»•i code cÅ©)

```python
# utilities/chunking_utils.py - File má»›i
import uuid
import logging

logger = logging.getLogger(__name__)

def should_chunk_patent(patent_text: str) -> bool:
    """Kiá»ƒm tra xem cÃ³ cáº§n chunking khÃ´ng"""
    return len(patent_text) > 2000  # 2KB threshold

def chunk_text_simple(text: str, chunk_type: str, patent_id: str) -> list:
    """Chia text thÃ nh chunks Ä‘Æ¡n giáº£n"""
    if not text or len(text) <= 1500:
        return []
    
    chunks = []
    chunk_size = 1500
    overlap = 100
    
    start = 0
    order = 0
    
    while start < len(text):
        end = min(start + chunk_size, len(text))
        
        # TÃ¬m boundary tá»‘t (cÃ¢u hoáº·c tá»«)
        if end < len(text):
            end = find_good_boundary(text, start, end)
        
        chunk_text = text[start:end]
        
        chunk = {
            "id": str(uuid.uuid4()),
            "patent_id": patent_id,
            "chunk_type": chunk_type,
            "chunk_order": order,
            "chunk_text": chunk_text,
            "chunk_size": len(chunk_text)
        }
        
        chunks.append(chunk)
        order += 1
        start = max(start + 1, end - overlap)
        
        if start >= len(text):
            break
    
    return chunks

def find_good_boundary(text: str, start: int, max_end: int) -> int:
    """TÃ¬m boundary tá»‘t Ä‘á»ƒ chia chunk"""
    # TÃ¬m dáº¥u cÃ¢u gáº§n nháº¥t
    for i in range(max_end, max(start, max_end - 200), -1):
        if i < len(text) and text[i] in '.!?;':
            return i + 1
    
    return max_end

def save_chunks_to_db(container, chunks: list, partition_key: str) -> bool:
    """LÆ°u chunks vÃ o database"""
    try:
        if not chunks:
            return True
        
        # Sá»­ dá»¥ng batch Ä‘á»ƒ tá»‘i Æ°u RU
        batch_size = 100
        for i in range(0, len(chunks), batch_size):
            batch_chunks = chunks[i:i + batch_size]
            
            # Táº¡o batch operations
            batch = container.create_transactional_batch(partition_key)
            for chunk in batch_chunks:
                batch.create_item(chunk)
            
            # Execute batch
            batch_result = batch.execute()
            if not batch_result.is_successful:
                logger.error(f"Failed to save chunk batch {i//batch_size}")
                return False
        
        return True
        
    except Exception as e:
        logger.error(f"Error saving chunks: {e}")
        return False

def get_chunks_from_db(container, patent_id: str) -> list:
    """Láº¥y chunks tá»« database"""
    try:
        query = "SELECT * FROM c WHERE c.patent_id = @patent_id AND c.chunk_type != null ORDER BY c.chunk_order"
        parameters = [{"name": "@patent_id", "value": patent_id}]
        
        chunks = list(container.query_items(
            query=query,
            parameters=parameters,
            enable_cross_partition_query=True
        ))
        
        return chunks
        
    except Exception as e:
        logger.error(f"Error getting chunks: {e}")
        return []

def reconstruct_patent_from_chunks(patent: dict, chunks: list) -> dict:
    """KhÃ´i phá»¥c patent tá»« chunks"""
    try:
        if not chunks:
            return patent
        
        # Group chunks theo type
        chunks_by_type = {}
        for chunk in chunks:
            chunk_type = chunk["chunk_type"]
            if chunk_type not in chunks_by_type:
                chunks_by_type[chunk_type] = []
            chunks_by_type[chunk_type].append(chunk)
        
        # Reconstruct tá»«ng field
        for chunk_type, type_chunks in chunks_by_type.items():
            # Sort theo order
            type_chunks.sort(key=lambda x: x["chunk_order"])
            
            # Combine text
            combined_text = " ".join([chunk["chunk_text"] for chunk in type_chunks])
            
            # Set vÃ o patent field
            if chunk_type == "abstract":
                patent["abstract"] = combined_text
            elif chunk_type == "claims":
                patent["claims"] = combined_text
            elif chunk_type == "description":
                patent["description"] = combined_text
        
        return patent
        
    except Exception as e:
        logger.error(f"Error reconstructing patent: {e}")
        return patent
```

### 2.2 Cáº­p nháº­t PatentInfo (chá»‰ thÃªm 2 fields)

```python
# models/patent_model.py - Chá»‰ thÃªm 2 fields má»›i
@dataclass
class PatentInfo:
    # ... existing fields (KHÃ”NG THAY Äá»”I) ...
    
    # Chá»‰ thÃªm 2 fields má»›i
    is_chunked: bool = False
    chunk_count: int = 0
    
    # ... existing methods (KHÃ”NG THAY Äá»”I) ...
```

### 2.3 Cáº­p nháº­t Patent DAO (chá»‰ thÃªm logic chunking)

```python
# dao/patent_dao.py - Chá»‰ thÃªm import vÃ  logic chunking
from utilities.chunking_utils import (
    should_chunk_patent, 
    chunk_text_simple, 
    save_chunks_to_db,
    get_chunks_from_db,
    reconstruct_patent_from_chunks
)

def create_patent(connection_string: str, database_name: str, container_name: str,
                  search_endpoint: str, search_key: str, search_index_name: str,
                  patent: PatentInfo) -> Optional[Exception]:
    """Create patent vá»›i chunking tá»± Ä‘á»™ng"""
    try:
        container = _get_container(connection_string, database_name, container_name)
        search_client = _get_search_client(search_endpoint, search_key, search_index_name)

        # Validate patent (KHÃ”NG THAY Äá»”I)
        if not patent.patent_id:
            raise ValueError("Patent ID is required")

        # Update timestamp (KHÃ”NG THAY Äá»”I)
        patent.update_timestamps()

        # === CHUNKING LOGIC Má»šI ===
        combined_text = _prepare_combined_text(patent)
        if should_chunk_patent(combined_text):
            logger.info(f"ğŸ”„ Applying chunking to patent {patent.patent_id}")
            
            # Táº¡o chunks
            all_chunks = []
            
            # Chunk abstract
            if patent.abstract:
                abstract_chunks = chunk_text_simple(patent.abstract, "abstract", patent.patent_id)
                all_chunks.extend(abstract_chunks)
            
            # Chunk claims
            if patent.claims:
                claims_chunks = chunk_text_simple(patent.claims, "claims", patent.patent_id)
                all_chunks.extend(claims_chunks)
            
            # Chunk description
            if patent.description:
                desc_chunks = chunk_text_simple(patent.description, "description", patent.patent_id)
                all_chunks.extend(desc_chunks)
            
            # LÆ°u chunks
            if all_chunks:
                if save_chunks_to_db(container, all_chunks, patent.patent_office):
                    patent.is_chunked = True
                    patent.chunk_count = len(all_chunks)
                    logger.info(f"âœ… Patent chunked into {len(all_chunks)} chunks")
                else:
                    logger.warning("âš ï¸ Failed to save chunks, continuing without chunking")
        
        # === EXISTING LOGIC (KHÃ”NG THAY Äá»”I) ===
        combined_text = _prepare_combined_text(patent)
        patent.combined_vector = generate_embeddings([combined_text])[0]

        if len(patent.combined_vector) != config.EMBEDDING_DIMENSION:
            raise ValueError(
                f"Embedding dimension mismatch: expected {config.EMBEDDING_DIMENSION}, got {len(patent.combined_vector)}"
            )
        
        # Prepare document (KHÃ”NG THAY Äá»”I)
        doc = _prepare_document_for_upload(patent)

        # Insert to Cosmos DB (KHÃ”NG THAY Äá»”I)
        container.create_item(body=doc)

        # Sync to Azure AI Search (KHÃ”NG THAY Äá»”I)
        try:
            search_client.upload_documents([doc])
            logger.info(f"âœ… Synced to Azure AI Search: {patent.patent_id}")
        except Exception as search_error:
            logger.warning(f"âš ï¸ Failed to sync to Azure AI Search: {search_error}")

        logger.info(f"âœ… Created Patent: {patent.patent_id}")
        return None
        
    except Exception as e:
        logger.error(f"âŒ Error creating Patent: {e}")
        return e

def read_patent(connection_string: str, database_name: str, container_name: str, 
                patent_id: str, reconstruct_chunks: bool = True) -> Optional[PatentInfo]:
    """Read patent vá»›i auto-reconstruction tá»« chunks"""
    try:
        container = _get_container(connection_string, database_name, container_name)

        # === EXISTING LOGIC (KHÃ”NG THAY Äá»”I) ===
        query = "SELECT * FROM c WHERE c.patent_id = @patent_id"
        parameters = [{"name": "@patent_id", "value": patent_id}]

        items = list(container.query_items(
            query=query,
            parameters=parameters,
            enable_cross_partition_query=True
        ))

        if items:
            patent_dict = items[0]
            
            # === CHUNKING LOGIC Má»šI ===
            if reconstruct_chunks and patent_dict.get("is_chunked"):
                logger.info(f"ğŸ”„ Reconstructing patent {patent_id} from chunks")
                
                # Láº¥y chunks
                chunks = get_chunks_from_db(container, patent_id)
                
                # Reconstruct
                if chunks:
                    patent_dict = reconstruct_patent_from_chunks(patent_dict, chunks)
                    logger.info(f"âœ… Patent {patent_id} reconstructed from {len(chunks)} chunks")
            
            # === EXISTING LOGIC (KHÃ”NG THAY Äá»”I) ===
            return PatentInfo.from_dict(patent_dict)
        else:
            logger.warning(f"âŒ Patent not found: {patent_id}")
            return None

    except Exception as e:
        logger.error(f"âŒ Error reading Patent: {e}")
        return None
```

## 3. Search Operations vá»›i Chunks

### 3.1 Text Search trong Chunks

```python
def search_in_chunks(connection_string: str, database_name: str, container_name: str,
                     search_text: str, limit: int = 10) -> List[Dict[str, Any]]:
    """Search text trong chunks"""
    try:
        container = _get_container(connection_string, database_name, container_name)
        
        # Search trong chunks
        query = """
        SELECT c.patent_id, c.chunk_text, c.chunk_type, c.chunk_order
        FROM c 
        WHERE CONTAINS(c.chunk_text, @search_text, true)
        ORDER BY c.chunk_size DESC
        LIMIT @limit
        """
        
        parameters = [
            {"name": "@search_text", "value": search_text},
            {"name": "@limit", "value": limit}
        ]
        
        chunks = list(container.query_items(
            query=query,
            parameters=parameters,
            enable_cross_partition_query=True
        ))
        
        # Group by patent_id
        results = []
        patent_chunks = {}
        
        for chunk in chunks:
            patent_id = chunk["patent_id"]
            if patent_id not in patent_chunks:
                patent_chunks[patent_id] = []
            patent_chunks[patent_id].append(chunk)
        
        # Convert to results
        for patent_id, chunk_list in patent_chunks.items():
            # Get patent info
            patent = read_patent(connection_string, database_name, container_name, 
                               patent_id, reconstruct_chunks=False)
            
            if patent:
                results.append({
                    "patent": patent,
                    "matching_chunks": chunk_list,
                    "total_matches": len(chunk_list)
                })
        
        return results[:limit]
        
    except Exception as e:
        logger.error(f"âŒ Error searching in chunks: {e}")
        return []
```

### 3.2 Cáº­p nháº­t existing search functions

```python
def basic_search(search_endpoint: str, search_key: str, search_index_name: str,
                 query: str, filters: List[SearchInfo] = [],
                 skip: int = 0, top: int = 10) -> List[Dict[str, Any]]:
    """Basic search vá»›i chunking support"""
    try:
        # === EXISTING LOGIC (KHÃ”NG THAY Äá»”I) ===
        search_client = _get_search_client(search_endpoint, search_key, search_index_name)
        filter_str = _build_filter_conditions(filters)
        
        results = search_client.search(
            search_text=query,
            filter=filter_str,
            top=top,
            skip=skip,
            include_total_count=True,
            select=["patent_id", "title", "abstract", "claims", "patent_office", "created_at", "updated_at"]
        )
        
        # === CHUNKING LOGIC Má»šI ===
        # Náº¿u káº¿t quáº£ Ã­t, search thÃªm trong chunks
        if len(results) < top:
            remaining = top - len(results)
            chunk_results = search_in_chunks(connection_string, database_name, container_name, 
                                          query, remaining)
            
            # Convert chunk results to same format
            for chunk_result in chunk_results:
                patent = chunk_result["patent"]
                results_list.append({
                    'patent': patent, 
                    'search_score': 0.8,  # Lower score for chunk results
                    'source': 'chunks'
                })
        
        # === EXISTING LOGIC (KHÃ”NG THAY Äá»”I) ===
        results_list = []
        for r in results:
            search_score = r.get('@search.score', 0.0)
            clean_result = {k: v for k, v in r.items() if not k.startswith('@search.')}
            patent = PatentInfo.from_dict(clean_result)
            results_list.append({'patent': patent, 'search_score': search_score, 'source': 'search_index'})
        
        return results_list
        
    except Exception as e:
        logger.error(f"âŒ Error in basic search: {e}")
        return []
```

## 4. Configuration Ä‘Æ¡n giáº£n

### 4.1 ThÃªm config cho chunking

```python
# config.py - Chá»‰ thÃªm 4 dÃ²ng
# ... existing config ...

# Chunking Configuration (má»›i)
CHUNKING_ENABLED = True
CHUNKING_THRESHOLD = 2000  # 2KB
MAX_CHUNK_SIZE = 1500      # 1.5KB per chunk
CHUNK_OVERLAP = 100        # 100 chars overlap
```

### 4.2 Sá»­ dá»¥ng config

```python
# utilities/chunking_utils.py
def should_chunk_patent(patent_text: str) -> bool:
    """Kiá»ƒm tra xem cÃ³ cáº§n chunking khÃ´ng"""
    if not config.CHUNKING_ENABLED:
        return False
    return len(patent_text) > config.CHUNKING_THRESHOLD

def chunk_text_simple(text: str, chunk_type: str, patent_id: str) -> list:
    """Chia text thÃ nh chunks Ä‘Æ¡n giáº£n"""
    if not text or len(text) <= config.MAX_CHUNK_SIZE:
        return []
    
    # ... existing logic vá»›i config values ...
```

## 5. Testing Ä‘Æ¡n giáº£n

### 5.1 Test functions

```python
# test_chunking.py
def test_chunking_functions():
    """Test cÃ¡c functions chunking"""
    
    # Test should_chunk_patent
    assert not should_chunk_patent("Short text")
    assert should_chunk_patent("A" * 2500)
    
    # Test chunk_text_simple
    long_text = "A" * 5000
    chunks = chunk_text_simple(long_text, "abstract", "test_id")
    assert len(chunks) > 1
    assert all(chunk["chunk_size"] <= 1500 for chunk in chunks)

def test_integration():
    """Test integration vá»›i existing code"""
    
    # Create large patent
    large_patent = PatentInfo(
        patent_id="test_chunking",
        title="Test",
        abstract="A" * 3000  # 3KB
    )
    
    # Test create (should trigger chunking)
    err = create_patent(conn_str, database_name, container_name,
                        search_endpoint, search_key, search_index_name, large_patent)
    assert err is None
    
    # Test read (should reconstruct)
    retrieved = read_patent(conn_str, database_name, container_name, "test_chunking")
    assert retrieved.abstract == large_patent.abstract
    assert retrieved.is_chunked == True
```

## 6. Migration Strategy

### 6.1 Gradual Rollout

```python
# Chá»‰ Ã¡p dá»¥ng cho patents má»›i
if config.CHUNKING_ENABLED:
    # Apply chunking logic
    pass

# Hoáº·c Ã¡p dá»¥ng cho patents cÃ³ content > threshold
if len(combined_text) > config.CHUNKING_THRESHOLD:
    # Apply chunking
    pass
```

### 6.2 Rollback Ä‘Æ¡n giáº£n

```python
def disable_chunking_for_patent(patent_id: str):
    """Disable chunking cho 1 patent"""
    try:
        # 1. Reconstruct patent
        patent = read_patent(conn_str, database_name, container_name, patent_id)
        
        # 2. Delete chunks
        container = _get_container(conn_str, database_name, container_name)
        query = "SELECT c.id FROM c WHERE c.patent_id = @patent_id AND c.chunk_type != null"
        parameters = [{"name": "@patent_id", "value": patent_id}]
        
        chunks = list(container.query_items(query=query, parameters=parameters))
        
        for chunk in chunks:
            container.delete_item(item=chunk["id"], partition_key=patent.patent_office)
        
        # 3. Update patent
        patent.is_chunked = False
        patent.chunk_count = 0
        
        update_patent(conn_str, database_name, container_name,
                     search_endpoint, search_key, search_index_name, patent)
        
        logger.info(f"âœ… Disabled chunking for patent {patent_id}")
        
    except Exception as e:
        logger.error(f"âŒ Error disabling chunking: {e}")
```

## 7. TÃ³m táº¯t thay Ä‘á»•i

### 7.1 Files má»›i
- `utilities/chunking_utils.py` - Chá»©a táº¥t cáº£ logic chunking

### 7.2 Files thay Ä‘á»•i
- `models/patent_model.py` - Chá»‰ thÃªm 2 fields: `is_chunked`, `chunk_count`
- `dao/patent_dao.py` - Chá»‰ thÃªm logic chunking vÃ o 2 functions: `create_patent`, `read_patent`
- `config.py` - Chá»‰ thÃªm 4 dÃ²ng config

### 7.3 Files KHÃ”NG thay Ä‘á»•i
- Táº¥t cáº£ search functions khÃ¡c
- Táº¥t cáº£ CRUD functions khÃ¡c
- Táº¥t cáº£ models khÃ¡c
- Táº¥t cáº£ utilities khÃ¡c

### 7.4 Lá»£i Ã­ch
- **Minimal code changes** - Chá»‰ thay Ä‘á»•i 3 files
- **Backward compatible** - Hoáº¡t Ä‘á»™ng vá»›i patents cÅ©
- **Simple approach** - KhÃ´ng OOP, chá»‰ functions
- **Easy to test** - Logic Ä‘Æ¡n giáº£n, dá»… test
- **Easy to rollback** - CÃ³ thá»ƒ disable dá»… dÃ ng

## 8. Káº¿t luáº­n

Approach nÃ y Ä‘áº£m báº£o:
1. **KhÃ´ng thay Ä‘á»•i** logic hiá»‡n táº¡i
2. **Chá»‰ thÃªm** chunking khi cáº§n thiáº¿t
3. **Dá»… implement** vÃ  test
4. **Dá»… maintain** vÃ  debug
5. **CÃ³ thá»ƒ rollback** náº¿u cáº§n

Vá»›i approach nÃ y, báº¡n cÃ³ thá»ƒ Ã¡p dá»¥ng chunking má»™t cÃ¡ch an toÃ n mÃ  khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n functionality hiá»‡n táº¡i cá»§a há»‡ thá»‘ng.
